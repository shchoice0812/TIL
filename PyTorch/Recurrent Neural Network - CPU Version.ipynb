{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Networks Transition to Recurrent Neural Networks\n",
    "* RNN is essentially an FNN\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86014019-c6010500-ba5a-11ea-8181-f31ccd004004.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/86013571-43784580-ba5a-11ea-9d3a-876703450c4f.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86013586-46733600-ba5a-11ea-920d-137c0114739c.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86014529-6a834700-ba5b-11ea-8759-965f3740217c.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/86014683-9dc5d600-ba5b-11ea-8094-55f85e5a7252.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015182-352b2900-ba5c-11ea-9f24-755add53c243.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015190-378d8300-ba5c-11ea-80cb-ce67c828ec78.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015202-39574680-ba5c-11ea-8d2e-d9cefde48c3b.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015220-3eb49100-ba5c-11ea-90ed-a36a9734c12b.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015921-23965100-ba5d-11ea-9667-f4b7cbca5012.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model A. Hidden Layer (ReLU)\n",
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 * 1\n",
    "    * Total per unroll: 28 * 28\n",
    "        * Feedforward Neural Network input size: 28 * 28\n",
    "* 1 Hidden layer\n",
    "* ReLU Activation Function\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86013571-43784580-ba5a-11ea-9d3a-876703450c4f.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86013586-46733600-ba5a-11ea-920d-137c0114739c.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86014529-6a834700-ba5b-11ea-8759-965f3740217c.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Step 1 : Load Dataset\n",
    "* Step 2 : Make Dataset Iterable\n",
    "* Step 3 : Create Model Class\n",
    "* Step 4 : Instantiate Model Class\n",
    "* Step 5 : Instantiate Loss Class\n",
    "* Step 6 : Instantiate Optimizer Class\n",
    "* Step 7 : Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.  Loading MNIST Train Dataset\n",
    "* images from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:23:46.501263Z",
     "start_time": "2020-06-29T14:23:42.164868Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:23:47.303177Z",
     "start_time": "2020-06-29T14:23:47.048800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train= True,\n",
    "                           transform= transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                          train=False,\n",
    "                          transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:24:10.611379Z",
     "start_time": "2020-06-29T14:24:10.605394Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:21.045877Z",
     "start_time": "2020-06-29T15:05:21.028922Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)) # x.size(0) = atch_dim\n",
    "        \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Instantiate Model Class\n",
    "* 28 time steps\n",
    "    * Each time step: input dimension = 28\n",
    "* 1 hidden layer\n",
    "* MNIST 1-9 digits -> output dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:22.532898Z",
     "start_time": "2020-06-29T15:05:22.527912Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:22.715410Z",
     "start_time": "2020-06-29T15:05:22.707431Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Instantiate Loss Class\n",
    "* Recurrent Neural Network: Cross Entropy Loss\n",
    "    * cf : Feedforward Nerual Network : Cross Entropy Loss\n",
    "    * cf : Linear Regression: MSE\n",
    "    * cf : Logistic Regression : Cross Entropy Loss\n",
    "    * cf : Convolutional Neural Network: Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:22.906898Z",
     "start_time": "2020-06-29T15:05:22.902908Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. instantiate Optimizer Class\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85815174-b8215a80-b7a2-11ea-917f-de5c35eb9ea9.png\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:23.161218Z",
     "start_time": "2020-06-29T15:05:23.155235Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameteres in Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:23.924177Z",
     "start_time": "2020-06-29T15:05:23.918195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input to Hidden Linear Function\n",
    "    * A1, B1\n",
    "* Hidden Layer to Output Linear Function\n",
    "    * A2, B2\n",
    "* Hidden Layer to Hidden Linear Function\n",
    "    *A3, B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:05:24.632283Z",
     "start_time": "2020-06-29T15:05:24.621312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Input -> Hidden (A1)\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Input -> Hidden Bias (B1)\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Hidden -> Hidden (A3)\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Hidden -> Hidden Bias (B3)\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Hidden -> Output (A2)\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Hidden -> Output Bias (B2)\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: Train a Model\n",
    "* process\n",
    "    1. Convert inputs/labels to variables\n",
    "        * RNN Input: (1, 28)\n",
    "        * CNN Input: (1, 28, 28)\n",
    "        * Feedforward NN Input: (1, 28*28)\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs\n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t parameters\n",
    "    6. Update parameters using gradients\n",
    "        * parameters = parameters - lr * parameters_gradients\n",
    "    7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:11:34.885133Z",
     "start_time": "2020-06-29T15:08:52.848674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.39562496542930603. Accuracy: 87\n",
      "Iteration: 1000. Loss: 0.3929261863231659. Accuracy: 89\n",
      "Iteration: 1500. Loss: 0.25924012064933777. Accuracy: 92\n",
      "Iteration: 2000. Loss: 0.19637300074100494. Accuracy: 92\n",
      "Iteration: 2500. Loss: 0.244120791554451. Accuracy: 93\n",
      "Iteration: 3000. Loss: 0.23553629219532013. Accuracy: 89\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)) # (batch_size, seq_dim, input_dim)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() -> 100, 10\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model B. Hidden Layer (ReLU)\n",
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 * 1\n",
    "    * Total per unroll: 28 * 28\n",
    "        * Feedforward Neural Network input size: 28 * 28\n",
    "* **2 Hidden layer**\n",
    "* ReLU Activation Function\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015220-3eb49100-ba5c-11ea-90ed-a36a9734c12b.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/86015921-23965100-ba5d-11ea-9667-f4b7cbca5012.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Step 1 : Load Dataset\n",
    "* Step 2 : Make Dataset Iterable\n",
    "* Step 3 : Create Model Class\n",
    "* **Step 4 : Instantiate Model Class**\n",
    "* Step 5 : Instantiate Loss Class\n",
    "* Step 6 : Instantiate Optimizer Class\n",
    "* Step 7 : Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:04:59.797323Z",
     "start_time": "2020-06-29T16:00:18.424465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 1.0093106031417847. Accuracy: 63\n",
      "Iteration: 1000. Loss: 0.8149239420890808. Accuracy: 76\n",
      "Iteration: 1500. Loss: 0.360173761844635. Accuracy: 88\n",
      "Iteration: 2000. Loss: 0.4796923100948334. Accuracy: 88\n",
      "Iteration: 2500. Loss: 0.09811796247959137. Accuracy: 94\n",
      "Iteration: 3000. Loss: 0.14625950157642365. Accuracy: 94\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "    \n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)) # (batch_size, seq_dim, input_dim)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() -> 100, 10\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 sets of parameters\n",
    "* First hidden Layer\n",
    "    * A1 = [100, 28]\n",
    "    * A3 = [100, 100]\n",
    "    * B1 = [100]\n",
    "    * B3 = [100]\n",
    "* Second hidden layer\n",
    "    * A2 = [100, 100]\n",
    "    * A5 = [100,100]\n",
    "    * B2 = [100]\n",
    "    * B5 = [100]\n",
    "* Readout layer\n",
    "    * A5 = [10, 100]\n",
    "    * B5 = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Step 1 : Load Dataset\n",
    "* Step 2 : Make Dataset Iterable\n",
    "* Step 3 : Create Model Class\n",
    "* **Step 4 : Instantiate Model Class**\n",
    "* Step 5 : Instantiate Loss Class\n",
    "* Step 6 : Instantiate Optimizer Class\n",
    "* Step 7 : Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model B. Hidden Layer (ReLU)\n",
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 * 1\n",
    "    * Total per unroll: 28 * 28\n",
    "        * Feedforward Neural Network input size: 28 * 28\n",
    "* 2 Hidden layer\n",
    "* **Tahh Activation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:29:02.672380Z",
     "start_time": "2020-06-29T16:24:53.340384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 0.5973575711250305. Accuracy: 80\n",
      "Iteration: 1000. Loss: 0.4522297978401184. Accuracy: 90\n",
      "Iteration: 1500. Loss: 0.18536020815372467. Accuracy: 93\n",
      "Iteration: 2000. Loss: 0.3356154263019562. Accuracy: 84\n",
      "Iteration: 2500. Loss: 0.1598687618970871. Accuracy: 95\n",
      "Iteration: 3000. Loss: 0.06450636684894562. Accuracy: 95\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "    \n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)) # (batch_size, seq_dim, input_dim)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() -> 100, 10\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results : Model A < Model B < Model C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "* 2 Ways to expand a nerual network\n",
    "    * More non-linear activation units(neurons)\n",
    "    * More hidden Layers\n",
    "* Cons\n",
    "    * Need a larger dataset\n",
    "        * CUrse of dimensionality\n",
    "    * Does not neccessarily higher accuarvy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
