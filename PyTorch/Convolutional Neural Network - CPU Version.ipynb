{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Basic Convolutional Nerual Network\n",
    "* Additional **Convolution** and **pooling** layers **before feedforward nerual network**\n",
    "* Layer with a **linear function & non-linearity: Fully Connected Layer**\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85870811-880ca280-b808-11ea-8964-61080c610bf3.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.2 One Convolutional Layer : High Level View Summary\n",
    "#### Gray Scale\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85873804-9ceb3500-b80c-11ea-8686-f0d0542a5d45.png\" align=left><br>\n",
    "* 커널이 왼쪽의 영상을 한번 다 sliding하고나면 오른쪽의 Feature Map1이 된다.\n",
    "* 또한 서로 다른 커널이 왼쪽의 영상을 돌면 Feature Map2가 되고 3이도히고 한다. 커널의 수 만큼 층이 깊어지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/85880139-7a5e1980-b816-11ea-90b8-991bd25c3c79.png\" align=left><br>\n",
    "* 커널이 움직이면서 다음과 같은 영상들을 얻었다고 하면 곱하고 summation을 하면서 8000이라는 값을 얻었다. => 즉 필터가 무언가를 detection 했다라고 해석하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/85880136-77fbbf80-b816-11ea-9f02-897ac051b88f.png\" align=left><br>\n",
    "* 커널을 곱하고 summation하면 0이 나온다. => 필터가 아무것도 detection하지 못했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Scale\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85873808-a07ebc00-b80c-11ea-9354-5648b4a2f1d6.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/85882389-2b19e800-b81a-11ea-9231-9554c31e0383.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85882400-2ce3ab80-b81a-11ea-8628-1776f6fb7a73.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85882526-62889480-b81a-11ea-8331-f8cafb381b86.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85882418-3240f600-b81a-11ea-8134-d52914b6529d.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the Kernel is sliding/convolving across the image -> 2 operations done per patch\n",
    "    1. Element-wise multiplication\n",
    "    2. Summation\n",
    "* More **kernels** = more feature map channels\n",
    "    * Can capture more information about the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Multiple Convoulutional Layers: High Level View\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85883826-92d13280-b81c-11ea-8ad4-27a3f1552174.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Pooling Layer: High Level View\n",
    "* 2 Common Types\n",
    "    * Max Pooling\n",
    "    * Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/60699771/85885341-2146b380-b81f-11ea-8372-dfa1dff53319.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85885329-1db32c80-b81f-11ea-9256-b500f452b0a3.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85885333-1ee45980-b81f-11ea-93b8-316728e590c0.png\" align=right>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85885335-20158680-b81f-11ea-9c1a-5422ac5f4486.png\" align=right>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85885338-20ae1d00-b81f-11ea-99fe-a4a0d1c00948.png\" align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Padding\n",
    "* Valid Padding(zero-padding)\n",
    "    * output size < input size\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85886046-4ab40f00-b820-11ea-8f31-9383c604ac88.PNG\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85886032-4687f180-b820-11ea-8fdb-68c3b7f5f12e.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85919055-1170b300-b8a3-11ea-8816-87ea4f4edd7d.png\" align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same Padding\n",
    "    * output size = Input size\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85886431-0f661000-b821-11ea-850a-ee35ce40685e.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85886434-11c86a00-b821-11ea-8c6e-da82f8867d3a.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85919059-12a1e000-b8a3-11ea-8b5c-1aabf9ad1a22.png\" align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Dimension Calculations\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85914122-8f1dca00-b875-11ea-9af2-5f8b6609b609.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model A\n",
    "* 2 Convolutional Layers\n",
    "    * Same Padding(same output size)\n",
    "* 2 Max Pooling Layers\n",
    "* 1 Fully Connected Layer\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85917676-2cd5c100-b897-11ea-9aa0-279c6dce6e9e.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Step 1 : Load Dataset\n",
    "* Step 2 : Make Dataset Iterable\n",
    "* Step 3 : Create Model Class\n",
    "* Step 4 : Instantiate Model Class\n",
    "* Step 5 : Instantiate Loss Class\n",
    "* Step 6 : Instantiate Optimizer Class\n",
    "* Step 7 : Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.  Loading MNIST Train Dataset\n",
    "* images from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T08:05:01.698530Z",
     "start_time": "2020-06-27T08:04:58.537986Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T08:05:02.294934Z",
     "start_time": "2020-06-27T08:05:01.985763Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train= True,\n",
    "                           transform= transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                          train=False,\n",
    "                          transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T08:05:45.537396Z",
     "start_time": "2020-06-27T08:05:45.528416Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Create Model Class\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85917676-2cd5c100-b897-11ea-9aa0-279c6dce6e9e.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Formula for Convolution\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85917888-00bb3f80-b899-11ea-80b6-59747dc6f2ac.png\" align=left>\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85918477-08c9ae00-b89e-11ea-85fb-bcf4e6059120.png\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:09:27.831225Z",
     "start_time": "2020-06-27T10:09:27.821253Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        ## in_channels : gray scale image, out_channel : number of kernels 즉, 16 feature maps를 의미\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Max Pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*7*7, 10) # (input dimension, output dimension)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        # Max pool 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original Size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New Out Size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:10:16.547896Z",
     "start_time": "2020-06-27T10:10:16.542907Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Instantiate Loss Class\n",
    "* Convolutional Neural Network: Cross Entropy Loss\n",
    "    * cf : Feedforward Nerual Network : Cross Entropy Loss\n",
    "    * cf : Linear Regression: MSE\n",
    "    * cf : Logistic Regression : Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:10:17.140310Z",
     "start_time": "2020-06-27T10:10:17.136319Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. instantiate Optimizer Class\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85815174-b8215a80-b7a2-11ea-917f-de5c35eb9ea9.png\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:10:17.667900Z",
     "start_time": "2020-06-27T10:10:17.662911Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameteres in Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:10:18.483717Z",
     "start_time": "2020-06-27T10:10:18.468756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000019447496448>\n",
      "6\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# Convolution 1: 16 Kernels\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Convolution 1 Bias: 16 Kernels\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Convolution 2: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Convolution 2 Bias: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Fully Connected Layer 1 Bias\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: Train a Model\n",
    "* process\n",
    "    1. Convert inputs/labels to variables\n",
    "        * CNN Input: (1, 28, 28)\n",
    "        * Feedforward NN Input: (1, 28*28)\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs\n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t parameters\n",
    "    6. Update parameters using gradients\n",
    "        * parameters = parameters - lr * parameters_gradients\n",
    "    7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:22:16.847496Z",
     "start_time": "2020-06-27T10:14:23.531166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.04474217817187309. Accuracy: 98\n",
      "Iteration: 1000. Loss: 0.07955381274223328. Accuracy: 98\n",
      "Iteration: 1500. Loss: 0.024444913491606712. Accuracy: 98\n",
      "Iteration: 2000. Loss: 0.011125444434583187. Accuracy: 98\n",
      "Iteration: 2500. Loss: 0.00814309436827898. Accuracy: 98\n",
      "Iteration: 3000. Loss: 0.01588745042681694. Accuracy: 98\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model B:\n",
    "* 2 Convolutional Layers\n",
    "    * Same Padding(same output size)\n",
    "* **2 Average Pooling Layers**\n",
    "* 1 Fully Connected Layer\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85920011-27827180-b8ab-11ea-9995-dddec6d6a27f.png\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:41:39.278554Z",
     "start_time": "2020-06-27T10:34:37.709385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.6100120544433594. Accuracy: 85\n",
      "Iteration: 1000. Loss: 0.38530197739601135. Accuracy: 89\n",
      "Iteration: 1500. Loss: 0.40377938747406006. Accuracy: 90\n",
      "Iteration: 2000. Loss: 0.24747291207313538. Accuracy: 91\n",
      "Iteration: 2500. Loss: 0.24004656076431274. Accuracy: 92\n",
      "Iteration: 3000. Loss: 0.4214174747467041. Accuracy: 93\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        ## in_channels : gray scale image, out_channel : number of kernels 즉, 16 feature maps를 의미\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Average pool 1\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Average Pool 2\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*7*7, 10) # (input dimension, output dimension)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        # Average pool 1\n",
    "        out = self.avgpool1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        # Average pool 2\n",
    "        out = self.avgpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original Size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New Out Size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out           \n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "model = CNNModel()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model C:\n",
    "* 2 Convolutional Layers\n",
    "    * **Valid Padding(smaller ouput size)**\n",
    "* **2 Max Pooling Layers**\n",
    "* 1 Fully Connected Layer\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85920320-a9739a00-b8ad-11ea-9f52-b56e9019cd99.png\" align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T10:46:50.362391Z",
     "start_time": "2020-06-27T10:41:55.070604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.3849509060382843. Accuracy: 88\n",
      "Iteration: 1000. Loss: 0.16876858472824097. Accuracy: 92\n",
      "Iteration: 1500. Loss: 0.20020459592342377. Accuracy: 94\n",
      "Iteration: 2000. Loss: 0.2095969170331955. Accuracy: 95\n",
      "Iteration: 2500. Loss: 0.18258501589298248. Accuracy: 96\n",
      "Iteration: 3000. Loss: 0.25763529539108276. Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        ## in_channels : gray scale image, out_channel : number of kernels 즉, 16 feature maps를 의미\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Max Pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*4*4, 10) # (input dimension, output dimension)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        # Max pool 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original Size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New Out Size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out                 \n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "model = CNNModel()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load Images as Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model.forward(images)\n",
    "        \n",
    "        # Calculate Loss: softmax -> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting Gradients w.r.t parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct /total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ※ Conclusioin : Model A > Model C > Model B\n",
    "<img src=\"https://user-images.githubusercontent.com/60699771/85920439-c9578d80-b8ae-11ea-9a3a-27a4e91c8fd5.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "* 3 Ways to expand a nerual network\n",
    "    * More convolutional layers\n",
    "    * Less aggressive downsampling\n",
    "        * Smaller kernel size for pooling(graduaally downsampling)\n",
    "    * More fully connected layers\n",
    "* Cons\n",
    "    * Need a larger dataset\n",
    "        * CUrse of dimensionality\n",
    "    * Does not neccessarily higher accuarvy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
